{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Preprocessing of UW-Madison Data\n",
    "## (into 3D numpy array)\n",
    "\n",
    "This file performs initial preprocessing of the UW-Madison dataset,\n",
    "starting with the data as provided for the Kaggle competition,\n",
    "and targeting 3D representation as a numpy array.\n",
    "\n",
    "The reason to target 3D representation from the earliest preprocessing step are:\n",
    "* Value clipping in 2D segmen done during preprocessing does not consider adjacent segments which may have values outside the curdrent image's range. This clipping approach will generate discontinuities in the depth dimension\n",
    "* Autmentations are limited to 2D, so 3D representation learning does not benefit fromaugmentation in the third dimension.\n",
    "* IoU/F1 score is strictly 2D, so the cost function does not reflect depth, and weight training does not benefit from depth.\n",
    "\n",
    "---\n",
    "\n",
    "The dataset comes from the UWMadison GI-Track Segmentation Kaggle Competition:\n",
    "* https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/\n",
    "\n",
    "The code here is largely copied/reused from an example provided by Kaggle competitor \"AWSAF49\"\n",
    "* https://www.kaggle.com/code/awsaf49/uwmgi-mask-data\n",
    "\n",
    "---\n",
    "\n",
    "The input to this script is the dataset as provided for the competition\n",
    "* 2.3G uw-madison-gi-tract-image-segmentation.zip\n",
    "\n",
    "Once unzipped it includes\n",
    "* MRI samples within a folder hierarchy which identifies the case (patient), day, and scan (slice).\n",
    "* A single \"training.csv\" file that contains run-length encoding (RLE) of 3 segments of the brain, for a subset of the images.\n",
    "\n",
    "An MRI is a set of scans that represent a 3D volume. Each scan is a 2D slice through the brain at a particular depth. Scans are in .png format and are a 16-bit grayscale image. Scans are co-located in the folder with it's peers for that MRI. \n",
    "\n",
    "A patient typically has several MRI samples, taken on different days.\n",
    "\n",
    "---\n",
    "\n",
    "This file performs the following:\n",
    "* RLE segmentation data for [large_bowel, small_bowel, stomach] is read and used to generate a 3D mask of dimensions [H,W,D] where H=heigh, W=width, and D=depth. Depth is the number of scans in the MRI. Each voxel is uint8 valued as:\n",
    "* 0 (binary 000) -> no classes\n",
    "* 1 (binary 001) -> class A\n",
    "* 2 (binary 010) -> class B\n",
    "* 3 (binary 011) -> class A, B\n",
    "* 4 (binary 100) -> class C\n",
    "* 5 (binary 101) -> class A, C\n",
    "* 6 (binary 110) -> class B, C\n",
    "* 7 (binary 111) -> class A, B, C\n",
    "\n",
    "The masks are written to file as .npy format.\n",
    "* Note that the above one-hot encoding does not present itself easily as RGB - so viewing the masks will require a bit more effort.\n",
    "\n",
    "In addition the grayscale MRI images are also re-written - here the \"slices\" are merged into a 3D numpy representation and written to a .npy file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights & Biases\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\" width=\"400\" alt=\"Weights & Biases\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# try:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     api_key = user_secrets.get_secret(\"WANDB\")\n",
    "#     wandb.login(key=api_key)\n",
    "# except:\n",
    "#     wandb.login(anonymous='must',relogin=True)\n",
    "#     print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = np.asarray(mask_rle.split(), dtype=int)\n",
    "    starts = s[0::2] - 1\n",
    "    lengths = s[1::2]\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2mask(id_, df=None):\n",
    "    idf = df[df['id']==id_]\n",
    "    wh = idf[['height','width']].iloc[0]\n",
    "    shape = (wh.height, wh.width, 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n",
    "        cdf = idf[idf['class']==class_]\n",
    "        rle = cdf.segmentation.squeeze()\n",
    "        if len(cdf) and not pd.isna(rle):\n",
    "            mask[..., i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "def rgb2gray(mask):\n",
    "    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n",
    "    gray_mask = pad_mask.argmax(-1)\n",
    "    return gray_mask\n",
    "\n",
    "def gray2rgb(mask):\n",
    "    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n",
    "    return rgb_mask[..., 1:].astype(mask.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Case/Segmentation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/d/code_medimg_practice/data/train.csv')\n",
    "# df = df.progress_apply(get_metadata, axis=1)\n",
    "df = df.apply(get_metadata, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge in Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob('/mnt/d/code_medimg_practice/data/train/*/*/*/*')\n",
    "path_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "# path_df = path_df.progress_apply(path2info, axis=1)\n",
    "path_df = path_df.apply(path2info, axis=1)\n",
    "df = df.merge(path_df, on=['case','day','slice'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=1; col=4\n",
    "plt.figure(figsize=(5*col,5*row))\n",
    "# the following line samples (row*col) unique IDs from that subset of the dataframe where \"segmentation\" is not N/A\n",
    "# In other words - get four samples that have segmentation\n",
    "for i, id_ in enumerate(df[~df.segmentation.isna()].sample(frac=1.0)['id'].unique()[:row*col]):\n",
    "    img = load_img(df[df['id']==id_].image_path.iloc[0])\n",
    "    mask = id2mask(id_,df=df)*255\n",
    "    plt.subplot(row, col, i+1)\n",
    "    i+=1\n",
    "    show_img(img, mask=mask)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporary - explore image and mask\n",
    "\n",
    "in summary: df includes (3) entries for each image (a.k.a. case_id) - one for each segment\n",
    "for example:\n",
    "```\n",
    "case34_day0_slice_0067\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "```\n",
    "### Image\n",
    "* An image is read from file using the load_img() function.\n",
    "* That function performs only basic processing - converting from uint16 to uint8, and cropping values\n",
    "* That function returns a numpy array of uint8 (between 0 and 255). Shape is variable.\n",
    "* Image pixel values are a skewed mostly lower values.\n",
    "\n",
    "### Mask\n",
    "* A \"mask\" is generated using the id2mask function.\n",
    "* That function:\n",
    "  * generates a zero array having [height, width] same as the image, but with additional dimension of [3]\n",
    "  * the pixels of that array are of type uint8\n",
    "  * for each of the (3) segmentation RLE sequences ['large_bowel', 'small_bowel', 'stomach']\n",
    "    * use the rle_decode to populate the array for that dimension \n",
    "  * the resulting array of shape [height, width, 3] having type uint8.\n",
    "  * the resulting array has pixel values of [0,1] indicating pixel is of that segment type. The application performs *255 resulting in pixel values of [0, 255].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore...\n",
    "\n",
    "# randomly sample from the dataframe, where segmentation is present, and choose the first\n",
    "case_id = df[~df.segmentation.isna()].sample(frac=1.0)['id'].unique()[0]\n",
    "print(case_id)\n",
    "\n",
    "for y in (df[df['id']==case_id].image_path):\n",
    "    print(y)\n",
    "\n",
    "img = load_img(df[df['id']==case_id].image_path.iloc[0])\n",
    "print(f\"\\ntype(img) {type(img)} img.shape {img.shape} type(img[0,0]) {type(img[0,0])}\")\n",
    "[print(y) for y in np.histogram(img)]\n",
    "\n",
    "\n",
    "mask = id2mask(case_id, df=df)\n",
    "print(f\"\\ntype(mask) {type(mask)} mask.shape {mask.shape} type(mask[0,0,0] {type(mask[0,0,0])}\")\n",
    "# [print(y) for y in np.histogram(mask[:,:,0])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,0])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,1])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,2])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Weights&Biases project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WANDB project\n",
    "run = wandb.init(project='uwmgi-mask-data', \n",
    "                 config={},\n",
    "#                  anonymous=anonymous,\n",
    "                 name=f\"01b_initial_preprocessing_to_3d_npy\",\n",
    "                )\n",
    "# Columns for wandb table\n",
    "columns=[\"id\", \"case\", \"day\", \"slice\", \"empty\", \"image\"]\n",
    "# Initialize table\n",
    "table = wandb.Table(columns=columns)\n",
    "# Labels for mask\n",
    "class_labels = {\n",
    "#     0:\"Background\",\n",
    "    1:\"Large Bowel\",\n",
    "    2:\"Small Bowel\",\n",
    "    3:\"Stomach\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Mask Set to Encoded Mask\n",
    "This function takes in 3 binary masks A, B, C and returns a single encoded mask.\n",
    "The output encoding considers that a pixel may be considered more than one class...\n",
    "```\n",
    "input:  np array of size [H,D,3] of ulong8 having value [0 or 1]\n",
    "output: np array of size [H,D]   of ulong8 having value (array[2]<<2 + array[1]<<1 + array[0]) where \"<<\" is bitwise shift left\n",
    "\n",
    "  * Input:                  Output:\n",
    "  * no classes            0 (binary 000)\n",
    "  * class A = 1           1 (binary 001)\n",
    "  * class B = 1           2 (binary 010)\n",
    "  * class A, B = 1        3 (binary 011)\n",
    "  * class C = 1           4 (binary 100)\n",
    "  * class A, C = 1        5 (binary 101)\n",
    "  * class B, C = 1        6 (binary 110)\n",
    "  * class A, B, C = 1     7 (binary 111)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mask_set(mask_in):\n",
    "    result = \\\n",
    "        np.left_shift(mask_in[:,:,2], 2) + \\\n",
    "        np.left_shift(mask_in[:,:,1], 1) + \\\n",
    "        np.left_shift(mask_in[:,:,0], 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(x) for x in np.histogram(mask[:,:,2])]\n",
    "# [print(x) for x in np.histogram(mask[:,:,1])]\n",
    "# [print(x) for x in np.histogram(mask[:,:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0]\n",
    "# df.info()\n",
    "# df.describe(include='all')\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write 3D masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO_EMPTY = True\n",
    "# # case = case122_day24_slice_0070\n",
    "\n",
    "# tmp_df = df.copy()\n",
    "# print(f\"NO_EMPTY={NO_EMPTY}\")\n",
    "# if NO_EMPTY:\n",
    "#     tmp_df = tmp_df[~df.segmentation.isna()]\n",
    "# ids = tmp_df['id'].unique()\n",
    "# ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_3d_mask_single_case_day(case, day, case_day_group):\n",
    "\n",
    "    SLICE_INDEXING_BASE = 1  # seriously - the slice index is 1-based... doh\n",
    "\n",
    "    height = case_day_group.iloc[0].height\n",
    "    width = case_day_group.iloc[0].width\n",
    "    depth = case_day_group.id.count() // 3\n",
    "    mri_mask = np.zeros((height, width, depth), dtype=np.uint8)\n",
    "\n",
    "    image_groups = case_day_group.groupby(['id'])[['class', 'slice', 'image_path']]\n",
    "    for (id), image_group in image_groups:\n",
    "        # print(id)\n",
    "        mask_onehot = id2mask(id, df=df)\n",
    "        mask_encoded = encode_mask_set(mask_onehot)\n",
    "        slice = image_group.slice.iloc[0] - SLICE_INDEXING_BASE\n",
    "        # print(slice)\n",
    "        mri_mask[:, :, slice] = mask_encoded\n",
    "\n",
    "    mask_folder = '/mnt/d/code_medimg_aneja_lab/data_uwmadison_01b_preprocessed_3D/masks'\n",
    "    mask_file = f\"{mask_folder}/case_{case}_day_{day}.npy\"\n",
    "\n",
    "    os.makedirs(mask_folder, exist_ok=True)\n",
    "    np.save(mask_file, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_3d_mask_all_case_and_days(df):\n",
    "\n",
    "    case_day_groups = df.groupby(['case', 'day'])[['slice', 'class', 'image_path', 'id', 'height', 'width']]\n",
    "\n",
    "    # for (case, day), case_day_group in case_day_groups:\n",
    "    #     save_3d_mask_single_case_day(case, day, case_day_group)\n",
    "\n",
    "    _ = Parallel(n_jobs=-1, backend='threading')(delayed(save_3d_mask_single_case_day)(case, day, case_day_group)\\\n",
    "                                                 for (case, day), case_day_group in case_day_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_3d_mask_all_case_and_days(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_r_cv2_u_madison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
