{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Preprocessing of UW-Madison Data\n",
    "## into 3D numpy array\n",
    "## cropping and padding to specified Height, Width, Depth\n",
    "\n",
    "This file performs initial preprocessing of the UW-Madison dataset,\n",
    "starting with the data as provided for the Kaggle competition,\n",
    "and targeting 3D representation as a numpy array.\n",
    "\n",
    "The reason to target 3D representation from the earliest preprocessing step are:\n",
    "* Value clipping in 2D segmen done during preprocessing does not consider adjacent segments which may have values outside the curdrent image's range. This clipping approach will generate discontinuities in the depth dimension\n",
    "* Autmentations are limited to 2D, so 3D representation learning does not benefit fromaugmentation in the third dimension.\n",
    "* IoU/F1 score is strictly 2D, so the cost function does not reflect depth, and weight training does not benefit from depth.\n",
    "\n",
    "---\n",
    "\n",
    "The dataset comes from the UWMadison GI-Track Segmentation Kaggle Competition:\n",
    "* https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/\n",
    "\n",
    "The code here is largely copied/reused from an example provided by Kaggle competitor \"AWSAF49\"\n",
    "* https://www.kaggle.com/code/awsaf49/uwmgi-mask-data\n",
    "\n",
    "---\n",
    "\n",
    "The input to this script is the dataset as provided for the competition\n",
    "* 2.3G uw-madison-gi-tract-image-segmentation.zip\n",
    "\n",
    "Once unzipped it includes\n",
    "* MRI samples within a folder hierarchy which identifies the case (patient), day, and scan (slice).\n",
    "* A single \"training.csv\" file that contains run-length encoding (RLE) of 3 segments of the brain, for a subset of the images.\n",
    "\n",
    "An MRI is a set of scans that represent a 3D volume. Each scan is a 2D slice through the brain at a particular depth. Scans are in .png format and are a 16-bit grayscale image. Scans are co-located in the folder with it's peers for that MRI. \n",
    "\n",
    "A patient typically has several MRI samples, taken on different days.\n",
    "\n",
    "---\n",
    "\n",
    "This file performs the following:\n",
    "* RLE segmentation data for [large_bowel, small_bowel, stomach] is read and used to generate a 3D mask of dimensions [H,W,D] where H=heigh, W=width, and D=depth. Depth is the number of scans in the MRI. Each voxel is uint8 valued as:\n",
    "* 0 (binary 000) -> no classes\n",
    "* 1 (binary 001) -> class A\n",
    "* 2 (binary 010) -> class B\n",
    "* 3 (binary 011) -> class A, B\n",
    "* 4 (binary 100) -> class C\n",
    "* 5 (binary 101) -> class A, C\n",
    "* 6 (binary 110) -> class B, C\n",
    "* 7 (binary 111) -> class A, B, C\n",
    "\n",
    "The masks are written to file as .npy format.\n",
    "* Note that the above one-hot encoding does not present itself easily as RGB - so viewing the masks will require a bit more effort.\n",
    "\n",
    "In addition the grayscale MRI images are also re-written - here the \"slices\" are merged into a 3D numpy representation and written to a .npy file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = np.asarray(mask_rle.split(), dtype=int)\n",
    "    starts = s[0::2] - 1\n",
    "    lengths = s[1::2]\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(row):\n",
    "    data = row['id'].split('_')\n",
    "    case = int(data[0].replace('case',''))\n",
    "    day = int(data[1].replace('day',''))\n",
    "    slice_ = int(data[-1])\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_\n",
    "    return row\n",
    "\n",
    "# /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png\n",
    "\n",
    "def path2info(row):\n",
    "    path = row['image_path']\n",
    "    path = path.split(\".png\")[0]\n",
    "    data = path.split('/')\n",
    "    slice_ = int(data[-1].split('_')[1])\n",
    "    case = int(data[-3].split('_')[0].replace('case',''))\n",
    "    day = int(data[-3].split('_')[1].replace('day',''))\n",
    "    width = int(data[-1].split('_')[2])\n",
    "    height = int(data[-1].split('_')[3])\n",
    "    width_mm_p_pix = float(data[-1].split('_')[4])\n",
    "    height_mm_p_pix = float(data[-1].split('_')[5])\n",
    "\n",
    "    row['case'] = case\n",
    "    row['day'] = day\n",
    "    row['slice'] = slice_    \n",
    "    row['height'] = height\n",
    "    row['width'] = width\n",
    "    row['height_mm_p_pix'] = height_mm_p_pix\n",
    "    row['width_mm_p_pix'] = width_mm_p_pix\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2mask(id_, df=None):\n",
    "    idf = df[df['id']==id_]\n",
    "    wh = idf[['height','width']].iloc[0]\n",
    "    shape = (wh.height, wh.width, 3)\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n",
    "        cdf = idf[idf['class']==class_]\n",
    "        rle = cdf.segmentation.squeeze()\n",
    "        if len(cdf) and not pd.isna(rle):\n",
    "            mask[..., i] = rle_decode(rle, shape[:2])\n",
    "    return mask\n",
    "\n",
    "def rgb2gray(mask):\n",
    "    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n",
    "    gray_mask = pad_mask.argmax(-1)\n",
    "    return gray_mask\n",
    "\n",
    "def gray2rgb(mask):\n",
    "    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n",
    "    return rgb_mask[..., 1:].astype(mask.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    img = img.astype('float32') # original is uint16\n",
    "    img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n",
    "    img = img.astype('uint8')\n",
    "    return img\n",
    "\n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Case/Segmentation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class segmentation  case  day  slice\n",
       "0  case123_day20_slice_0001  large_bowel          NaN   123   20      1\n",
       "1  case123_day20_slice_0001  small_bowel          NaN   123   20      1\n",
       "2  case123_day20_slice_0001      stomach          NaN   123   20      1\n",
       "3  case123_day20_slice_0002  large_bowel          NaN   123   20      2\n",
       "4  case123_day20_slice_0002  small_bowel          NaN   123   20      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/d/code_medimg_practice/data/train.csv')\n",
    "# df = df.progress_apply(get_metadata, axis=1)\n",
    "df = df.apply(get_metadata, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge in Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>case</th>\n",
       "      <th>day</th>\n",
       "      <th>slice</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>height_mm_p_pix</th>\n",
       "      <th>width_mm_p_pix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>/mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>/mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>/mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class segmentation  case  day  slice  \\\n",
       "0  case123_day20_slice_0001  large_bowel          NaN   123   20      1   \n",
       "1  case123_day20_slice_0001  small_bowel          NaN   123   20      1   \n",
       "2  case123_day20_slice_0001      stomach          NaN   123   20      1   \n",
       "3  case123_day20_slice_0002  large_bowel          NaN   123   20      2   \n",
       "4  case123_day20_slice_0002  small_bowel          NaN   123   20      2   \n",
       "\n",
       "                                                                                            image_path  \\\n",
       "0  /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png   \n",
       "1  /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png   \n",
       "2  /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0001_266_266_1.50_1.50.png   \n",
       "3  /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png   \n",
       "4  /mnt/d/code_medimg_practice/data/train/case123/case123_day20/scans/slice_0002_266_266_1.50_1.50.png   \n",
       "\n",
       "   height  width  height_mm_p_pix  width_mm_p_pix  \n",
       "0     266    266              1.5             1.5  \n",
       "1     266    266              1.5             1.5  \n",
       "2     266    266              1.5             1.5  \n",
       "3     266    266              1.5             1.5  \n",
       "4     266    266              1.5             1.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob('/mnt/d/code_medimg_practice/data/train/*/*/*/*')\n",
    "path_df = pd.DataFrame(paths, columns=['image_path'])\n",
    "path_df = path_df.apply(path2info, axis=1)\n",
    "df = df.merge(path_df, on=['case','day','slice'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path    274\n",
      "dtype: int64\n",
      "image_path    15\n",
      "dtype: int64\n",
      "image_path    259\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Question: what is the 'depth' i.e. how many images are in a case_day ?\n",
    "# Answer - the depth dimension is either 144 (259 of these) or 80 (15 of these). There are a total of 274 case-days.\n",
    "grouped = path_df.groupby(['case', 'day'])[['image_path']].count()\n",
    "\n",
    "print(grouped.count())\n",
    "\n",
    "condition = grouped['image_path'] == 80\n",
    "print(grouped[condition].count())\n",
    "\n",
    "condition = grouped['image_path'] == 144\n",
    "print(grouped[condition].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heights are [266 310 276 234] and widths are [266 360 276 234]\n"
     ]
    }
   ],
   "source": [
    "# Question: what are the common heights and widths ?\n",
    "print(f\"heights are {path_df['height'].unique()} and widths are {path_df['width'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images 38496\n",
      "266x266 25920\n",
      "310x360 11232\n",
      "276x276 1200\n",
      "234x236 144\n",
      "38496\n"
     ]
    }
   ],
   "source": [
    "# Are there specific height/width combinations?\n",
    "# yes there are 4 combinations:\n",
    "# 266x266 25920\n",
    "# 310x360 11232\n",
    "# 276x276 1200\n",
    "# 234x236 144\n",
    "\n",
    "condition_01 = path_df['height']==266\n",
    "condition_02 = path_df['height']==310\n",
    "condition_03 = path_df['height']==276\n",
    "condition_04 = path_df['height']==234\n",
    "\n",
    "condition_10 = path_df['width']==266\n",
    "condition_20 = path_df['width']==360\n",
    "condition_30 = path_df['width']==276\n",
    "condition_40 = path_df['width']==234\n",
    "\n",
    "print(f\"total images {path_df['image_path'].count()}\")\n",
    "print(f\"266x266 {path_df['image_path'][condition_01 & condition_10].count()}\")\n",
    "print(f\"310x360 {path_df['image_path'][condition_02 & condition_20].count()}\")\n",
    "print(f\"276x276 {path_df['image_path'][condition_03 & condition_30].count()}\")\n",
    "print(f\"234x236 {path_df['image_path'][condition_04 & condition_40].count()}\")\n",
    "\n",
    "print(25920+11232+1200+144)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporary - explore image and mask\n",
    "\n",
    "in summary: df includes (3) entries for each image (a.k.a. case_id) - one for each segment\n",
    "for example:\n",
    "```\n",
    "case34_day0_slice_0067\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "/mnt/d/code_medimg_practice/data/train/case34/case34_day0/scans/slice_0067_276_276_1.63_1.63.png\n",
    "```\n",
    "### Image\n",
    "* An image is read from file using the load_img() function.\n",
    "* That function performs only basic processing - converting from uint16 to uint8, and cropping values\n",
    "* That function returns a numpy array of uint8 (between 0 and 255). Shape is variable.\n",
    "* Image pixel values are a skewed mostly lower values.\n",
    "\n",
    "### Mask\n",
    "* A \"mask\" is generated using the id2mask function.\n",
    "* That function:\n",
    "  * generates a zero array having [height, width] same as the image, but with additional dimension of [3]\n",
    "  * the pixels of that array are of type uint8\n",
    "  * for each of the (3) segmentation RLE sequences ['large_bowel', 'small_bowel', 'stomach']\n",
    "    * use the rle_decode to populate the array for that dimension \n",
    "  * the resulting array of shape [height, width, 3] having type uint8.\n",
    "  * the resulting array has pixel values of [0,1] indicating pixel is of that segment type. The application performs *255 resulting in pixel values of [0, 255].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case129_day0_slice_0111\n",
      "/mnt/d/code_medimg_practice/data/train/case129/case129_day0/scans/slice_0111_360_310_1.50_1.50.png\n",
      "/mnt/d/code_medimg_practice/data/train/case129/case129_day0/scans/slice_0111_360_310_1.50_1.50.png\n",
      "/mnt/d/code_medimg_practice/data/train/case129/case129_day0/scans/slice_0111_360_310_1.50_1.50.png\n",
      "\n",
      "type(img) <class 'numpy.ndarray'> img.shape (310, 360) type(img[0,0]) <class 'numpy.uint8'>\n",
      "[84681 10371  6194  5247  3358  1204   343   144    44    14]\n",
      "[  0.   25.5  51.   76.5 102.  127.5 153.  178.5 204.  229.5 255. ]\n",
      "\n",
      "type(mask) <class 'numpy.ndarray'> mask.shape (310, 360, 3) type(mask[0,0,0] <class 'numpy.uint8'>\n",
      "[109393      0      0      0      0      0      0      0      0   2207]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "[108849      0      0      0      0      0      0      0      0   2751]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "[     0      0      0      0      0 111600      0      0      0      0]\n",
      "[-0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3  0.4  0.5]\n"
     ]
    }
   ],
   "source": [
    "### explore...\n",
    "\n",
    "# randomly sample from the dataframe, where segmentation is present, and choose the first\n",
    "case_id = df[~df.segmentation.isna()].sample(frac=1.0)['id'].unique()[0]\n",
    "print(case_id)\n",
    "\n",
    "for y in (df[df['id']==case_id].image_path):\n",
    "    print(y)\n",
    "\n",
    "img = load_img(df[df['id']==case_id].image_path.iloc[0])\n",
    "print(f\"\\ntype(img) {type(img)} img.shape {img.shape} type(img[0,0]) {type(img[0,0])}\")\n",
    "[print(y) for y in np.histogram(img)]\n",
    "\n",
    "\n",
    "mask = id2mask(case_id, df=df)\n",
    "print(f\"\\ntype(mask) {type(mask)} mask.shape {mask.shape} type(mask[0,0,0] {type(mask[0,0,0])}\")\n",
    "# [print(y) for y in np.histogram(mask[:,:,0])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,0])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,1])]\n",
    "_ = [print(y) for y in np.histogram(mask[:,:,2])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Mask Set to Encoded Mask\n",
    "This function takes in 3 binary masks A, B, C and returns a single encoded mask.\n",
    "The output encoding considers that a pixel may be considered more than one class...\n",
    "```\n",
    "input:  np array of size [H,D,3] of ulong8 having value [0 or 1]\n",
    "output: np array of size [H,D]   of ulong8 having value (array[2]<<2 + array[1]<<1 + array[0]) where \"<<\" is bitwise shift left\n",
    "\n",
    "  * Input:                  Output:\n",
    "  * no classes            0 (binary 000)\n",
    "  * class A = 1           1 (binary 001)\n",
    "  * class B = 1           2 (binary 010)\n",
    "  * class A, B = 1        3 (binary 011)\n",
    "  * class C = 1           4 (binary 100)\n",
    "  * class A, C = 1        5 (binary 101)\n",
    "  * class B, C = 1        6 (binary 110)\n",
    "  * class A, B, C = 1     7 (binary 111)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_mask_set(mask_in):\n",
    "    result = \\\n",
    "        np.left_shift(mask_in[:,:,2], 2) + \\\n",
    "        np.left_shift(mask_in[:,:,1], 1) + \\\n",
    "        np.left_shift(mask_in[:,:,0], 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(x) for x in np.histogram(mask[:,:,2])]\n",
    "# [print(x) for x in np.histogram(mask[:,:,1])]\n",
    "# [print(x) for x in np.histogram(mask[:,:,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0]\n",
    "# df.info()\n",
    "# df.describe(include='all')\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write 3D mask, image (cropped and padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-dimensional crop and pad\n",
    "# given a source size, and target size,\n",
    "# determine start and end IDs source for a copy of source into target\n",
    "# such that the source will end up centered in the target\n",
    "#\n",
    "# if the source is larger than target then crop the source indexes\n",
    "# if the source is smaller than target then adjust the target indexes to center it\n",
    "\n",
    "def pad_and_crop_idx(source_size, target_size):\n",
    "    if source_size < target_size:  # pick the smaller\n",
    "        the_size = source_size\n",
    "    else:\n",
    "        the_size = target_size\n",
    "\n",
    "    half_size = the_size // 2\n",
    "    source_mid_idx = source_size // 2\n",
    "    target_mid_idx = target_size // 2\n",
    "\n",
    "    source_start_idx = source_mid_idx - half_size\n",
    "    source_end_idx = source_start_idx + the_size - 1\n",
    "    target_start_idx = target_mid_idx - half_size\n",
    "    target_end_idx = target_start_idx + the_size - 1\n",
    "\n",
    "    return source_start_idx, source_end_idx, target_start_idx, target_end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_3d_mask_single_case_day(base_folder, case, day, case_day_group, target_height, target_width, target_depth):\n",
    "\n",
    "    SLICE_INDEXING_BASE = 1  # seriously - the slice index is 1-based... doh\n",
    "\n",
    "    source_height = case_day_group.iloc[0].height\n",
    "    source_width = case_day_group.iloc[0].width\n",
    "    source_depth = case_day_group.id.count() // 3\n",
    "\n",
    "    print(f'source_h {source_height} source_w {source_width} source_d {source_depth} target_h {target_height} target_w {target_width} target_d {target_depth}')\n",
    "\n",
    "    src_start_h, src_end_h, tar_start_h, tar_end_h = pad_and_crop_idx(source_height, target_height)\n",
    "    src_start_w, src_end_w, tar_start_w, tar_end_w = pad_and_crop_idx(source_width, target_width)\n",
    "    src_start_d, src_end_d, tar_start_d, tar_end_d = pad_and_crop_idx(source_depth, target_depth)\n",
    "   \n",
    "    # case-day grouped by \"ID\" (3 rows all referring to same image, different masks)\n",
    "    image_groups = case_day_group.groupby(['id'])[['class', 'slice', 'image_path']]\n",
    "\n",
    "    base_folder = f\"{base_folder}_{target_height}_{target_width}_{target_depth}\"\n",
    "\n",
    "    # 3d masks\n",
    "    mask_3d_full = np.zeros((source_height, source_width, source_depth), dtype=np.uint8)\n",
    "    for (id), image_group in image_groups:\n",
    "        mask_onehot = id2mask(id, df=df)  # returns 3 masks (one-hot)\n",
    "        mask_encoded = encode_mask_set(mask_onehot)  # returns a single mask (encoded) \n",
    "        slice = image_group.slice.iloc[0] - SLICE_INDEXING_BASE\n",
    "        mask_3d_full[:, :, slice] = mask_encoded\n",
    "    # crop and pad...\n",
    "    mask_3d_crpd = np.zeros((target_height, target_width, target_depth), dtype=np.uint8)\n",
    "    mask_3d_crpd[tar_start_h:tar_end_h+1, tar_start_w:tar_end_w+1, tar_start_d:tar_end_d+1] = (\n",
    "        mask_3d_full[src_start_h:src_end_h+1, src_start_w:src_end_w+1, src_start_d:src_end_d+1])\n",
    "\n",
    "    mask_folder = f\"{base_folder}/masks\"\n",
    "    os.makedirs(mask_folder, exist_ok=True)\n",
    "    mask_file = f\"{mask_folder}/case_{case}_day_{day}.npy\"\n",
    "    np.save(mask_file, mask_3d_crpd)\n",
    "\n",
    "    # 3d images\n",
    "    image_3d_full = np.zeros((source_height, source_width, source_depth), dtype=np.uint8)\n",
    "    for (id), image_group in image_groups:\n",
    "        slice = image_group.slice.iloc[0] - SLICE_INDEXING_BASE\n",
    "        image_2d = image_group.image_path.unique()[0]\n",
    "        single_image = load_img(image_2d)\n",
    "        image_3d_full[:, :, slice] = single_image\n",
    "    # crop and pad\n",
    "    image_3d_crpd = np.zeros((target_height, target_width, target_depth), dtype=np.uint8)\n",
    "    image_3d_crpd[tar_start_h:tar_end_h+1, tar_start_w:tar_end_w+1, tar_start_d:tar_end_d+1] = (\n",
    "        image_3d_full[src_start_h:src_end_h+1, src_start_w:src_end_w+1, src_start_d:src_end_d+1])\n",
    "\n",
    "    image_folder = f\"{base_folder}/images\"\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    image_file = f\"{image_folder}/case_{case}_day_{day}.npy\"\n",
    "    np.save(image_file, image_3d_crpd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_3d_mask_all_case_and_days(df):\n",
    "\n",
    "\n",
    "    base_folder = f'/mnt/d/code_medimg_aneja_lab/data_uwmadison_01c_preprocessed_3d_masked_and_padded_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}'\n",
    "    \n",
    "    case_day_groups = df.groupby(['case', 'day'])[['slice', 'class', 'image_path', 'id', 'height', 'width']]\n",
    "\n",
    "    # for (case, day), case_day_group in case_day_groups:\n",
    "    #     save_3d_mask_single_case_day(case, day, case_day_group)\n",
    "\n",
    "    SCALE = 4\n",
    "    output_height = 310 // SCALE\n",
    "    output_width = 360 // SCALE\n",
    "    output_depth = 144 // SCALE\n",
    "\n",
    "    _ = Parallel(n_jobs=-1, backend='threading')(delayed(save_3d_mask_single_case_day)(base_folder, case, day, case_day_group,\\\n",
    "                                                                                       output_height, output_width, output_depth)\\\n",
    "                                                 for (case, day), case_day_group in case_day_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 276 source_w 276 source_d 80 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 266 source_w 266 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n",
      "source_h 310 source_w 360 source_d 144 target_h 310 target_w 360 target_d 144\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m save_3d_mask_all_case_and_days(df)\n",
      "\u001b[1;32m/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output_depth \u001b[39m=\u001b[39m \u001b[39m144\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m SCALE \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m _ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, backend\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mthreading\u001b[39;49m\u001b[39m'\u001b[39;49m)(delayed(save_3d_mask_single_case_day)(base_folder, case, day, case_day_group,\\\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m                                                                                    output_height, output_width, output_depth)\\\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/d/code_medimg_aneja_lab/medical_image_aneja_lab/uwmadison_01c_preprocess_rle_to_3d_unit_preserved.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                                              \u001b[39mfor\u001b[39;49;00m (case, day), case_day_group \u001b[39min\u001b[39;49;00m case_day_groups)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_r_cv2_u_madison/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_r_cv2_u_madison/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_r_cv2_u_madison/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_3d_mask_all_case_and_days(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Image Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_3d(folder, subfolder, case_day):    \n",
    "    path = f\"{folder}/{subfolder}/{case_day}.npy\"\n",
    "    # print(path)\n",
    "    img = np.load(path, encoding='bytes')\n",
    "    return img\n",
    "\n",
    "def show_3d(folder, case_day, num_wanted, show_mask, scale):\n",
    "\n",
    "    image_3d = load_3d(folder, \"images\", case_day)\n",
    "    if show_mask:\n",
    "        mask_3d = load_3d(folder, \"masks\", case_day)\n",
    "\n",
    "    max_slice = image_3d.shape[2]\n",
    "    if num_wanted== -1:\n",
    "        num_wanted = max_slice + 1\n",
    "    # slices = [max_slice  * (sample_num + 1)  // (num_wanted+1) for sample_num in range(num_wanted)]\n",
    "    slices = [92] # zona\n",
    "    print(f\"slices {slices}\")\n",
    "\n",
    "    nrows = len(slices)\n",
    "    ncols = 2\n",
    "    plt.figure(1)\n",
    "    fix, axs = plt.subplots(nrows, ncols, figsize=(ncols*scale, nrows*scale),\n",
    "                            subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "    index = 0\n",
    "    for slice in slices:\n",
    "\n",
    "        index += 1\n",
    "        plt.subplot(nrows, ncols, index)\n",
    "        plt.title(f\"Slice {slice}\")\n",
    "\n",
    "        image_2d = image_3d[:, :, slice]\n",
    "        plt.imshow(image_2d,  interpolation='none', cmap='bone')\n",
    "        # plt.imshow(image_2d)\n",
    "\n",
    "        index += 1\n",
    "        if show_mask:\n",
    "            mask_2d = mask_3d[:, :, slice]\n",
    "            counts, buckets = np.histogram(mask_2d, bins=256, range=(-0.5, 255.5))\n",
    "            count_string = (f\"noclass:{counts[0]}\\n\" +\n",
    "                            f\"a:{counts[1]} b:{counts[2]} c:{counts[4]}\\n\" +\n",
    "                            f\"ab:{counts[3]} ac:{counts[5]} bc:{counts[6]} abc:{counts[7]}\")\n",
    "\n",
    "            # mask_2d_normalized = mask_3d_normalized[:, :, slice]\n",
    "            # print(np.histogram(mask_2d, bins=8, range=(-0.5, 7.5)))\n",
    "        \n",
    "            plt.subplot(nrows, ncols, index)\n",
    "            plt.title(count_string, loc='left')\n",
    "            # plt.imshow(mask_2d_normalized)\n",
    "            # plt.imshow(mask_2d_normalized, cmap='bone')\n",
    "            # plt.imshow(mask_2d, cmap = plt.colormaps[\"plasma\"])\n",
    "            # plt.imshow(mask_2d, cmap = plt.colormaps[\"inferno\"])\n",
    "            # plt.imshow(mask_2d, vmin=0, vmax=7, cmap = plt.colormaps[\"magma\"])\n",
    "            plt.imshow(mask_2d, vmin=0, vmax=7, interpolation='none', cmap = plt.colormaps[\"nipy_spectral\"])\n",
    "\n",
    "\n",
    "        #     # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        #     plt.imshow(mask, alpha=0.5)\n",
    "        #     handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        #     labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        #     plt.legend(handles,labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 3D Image (series of 2D slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/mnt/d/code_medimg_aneja_lab/data_uwmadison_01c_preprocessed_3d'\n",
    "case_day = 'case_85_day_29'\n",
    "show_3d(base_folder, case_day, num_wanted=-1, show_mask=True, scale=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing 3D\n",
    "\n",
    "https://www.geeksforgeeks.org/displaying-3d-images-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    " \n",
    "# Change the Size of Graph using \n",
    "# Figsize\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    " \n",
    "# Generating a 3D sine wave\n",
    "ax = plt.axes(projection='3d')\n",
    " \n",
    "# Creating array points using \n",
    "# numpy\n",
    "x = np.arange(0, 20, 0.1)\n",
    "y = np.sin(x)\n",
    "z = y*np.sin(x)\n",
    "c = x + y\n",
    " \n",
    "# To create a scatter graph\n",
    "ax.scatter(x, y, z, c=c)\n",
    " \n",
    "# turn off/on axis\n",
    "plt.axis('off')\n",
    " \n",
    "# show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# import numpy as np\n",
    " \n",
    "# Change the Size of Graph using \n",
    "# Figsize\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    " \n",
    "# Generating a 3D sine wave\n",
    "ax = plt.axes(projection='3d')\n",
    " \n",
    "# Create axis\n",
    "axes = [5, 5, 5]\n",
    " \n",
    "# Create Data\n",
    "data = np.ones(axes)\n",
    " \n",
    "# Control Tranperency\n",
    "alpha = 0.7\n",
    " \n",
    "# Control colour\n",
    "colors = np.empty(axes + [4])\n",
    " \n",
    "colors[0] = [1, 0, 0, alpha]  # red\n",
    "colors[1] = [0, 1, 0, alpha]  # green\n",
    "colors[2] = [0, 0, 1, alpha]  # blue\n",
    "colors[3] = [1, 1, 0, alpha]  # yellow\n",
    "colors[4] = [1, 1, 1, alpha]  # grey\n",
    " \n",
    "# turn off/on axis\n",
    "plt.axis('off')\n",
    " \n",
    "# Voxels is used to customizations of\n",
    "# the sizes, positions and colors.\n",
    "_ = ax.voxels(data, facecolors=colors, edgecolors='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    " \n",
    "#Change the Size of Graph using Figsize\n",
    "fig = plt.figure(figsize=(10,10))\n",
    " \n",
    "#Generating a 3D sine wave\n",
    "ax = plt.axes(projection='3d')\n",
    " \n",
    " \n",
    "# assigning coordinates \n",
    "x = np.linspace(-1, 5, 10)\n",
    "y = np.linspace(-1, 5, 10)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "# Z = np.sin(np.sqrt(X ** 2 + Y ** 2))\n",
    "Z = np.ones((len(x), len(x)))\n",
    " \n",
    "# creating the visualization\n",
    "ax.plot_wireframe(X, Y, Z, color ='green')\n",
    " \n",
    "# turn off/on axis\n",
    "plt.axis('on')\n",
    "plt.title(\"Whatever\")\n",
    "plt.xlabel(\"The X\")\n",
    "plt.ylabel(\"The Y\")\n",
    "plt.zlabel(\"The Z\")\n",
    "plt.set_zlabel(\"foo\")\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import linspace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    " \n",
    " \n",
    "# Creating 3D figure\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = plt.axes(projection='3d')\n",
    " \n",
    "# Creating Dataset\n",
    "z = np.linspace(0, 15, 1000)\n",
    "x = np.sin(z)\n",
    "y = np.cos(z)\n",
    "_ = ax.plot3D(x, y, z, 'green')\n",
    " \n",
    "# 360 Degree view\n",
    "for angle in range(0, 360):\n",
    "    _ = ax.view_init(angle, 30)\n",
    "    _ = plt.draw()\n",
    "    _ = plt.pause(.1)\n",
    " \n",
    "    _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_r_cv2_u_madison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
